# Hiring Assistant Â· Agentic HR Planner

Plan a startup hiring process from a single prompt.

- **Clarifies the ask** (basic parsing of multiple roles)
- **Drafts Job Descriptions (JDs)** from templates with **optional LLM polish**
- **Creates a hiring checklist & interview loop** (Markdown + JSON)
- **Flags non-inclusive language** and provides **outreach email templates**
- **Exports**: `plan.md`, `plan.json`, and **HR-friendly `plan.docx`**
- **LangGraph** orchestrated, **Streamlit** UI, **Docker** ready, **AWS EB** deployable

> This project is for the Squareshift â€œAgent in Action â€“ GenAI Builder-in-Residence Challengeâ€.  
> It intentionally uses deterministic stubs + optional LLM refinement to keep demos fast and repeatable.

---

## Demo (What it does)

1. Enter a prompt like:  
   _â€œI need to hire a founding engineer and a GenAI intern. Can you help?â€_
2. Click **Plan Hiring**.
3. The app:
   - Parses roles
   - Loads role facts from `/data/role_knowledge`
   - Builds structured **JDs** (and optionally polishes wording via OpenAI)
   - Emits a **Checklist + Interview Loop** (Markdown + JSON)
   - Flags **inclusive-language issues** and drafts **outreach emails**
4. Export everything as **MD/JSON/DOCX**.

---

## Stack

- **UI**: Streamlit
- **Agent Orchestration**: LangGraph
- **Models**: Pydantic (state + schemas)
- **LLM (optional)**: OpenAI (Chat Completions)
- **Exports**: `python-docx` for `.docx`
- **Packaging/Deploy**: Docker; AWS Elastic Beanstalk (ALB + ACM), Route 53

---

## Project Structure


```
HiringAssistant/
â”œâ”€ app/
â”‚ â”œâ”€ ui.py # Streamlit shell; kicks off role review and renders Tabs (1â€“4)
â”‚ â”œâ”€ init.py
â”‚ â”œâ”€ tabs/
â”‚ â”‚ â”œâ”€ init.py
â”‚ â”‚ â””â”€ roles_tab.py # Tab 1 orchestration:
â”‚ â”‚ # â€¢ Review role suggestions
â”‚ â”‚ # â€¢ Add another hiring role (search/select or create custom)
â”‚ â”‚ # â€¢ Edit matched roles (inline); remove role from the plan
â”‚ â”‚ # â€¢ "Generate plan & JDs" (rebuilds JD + plan only after roles finalized)
â”‚ â”œâ”€ components/
â”‚ â”‚ â”œâ”€ init.py
â”‚ â”‚ â”œâ”€ matched_role_editor.py # Editor for matched roles:
â”‚ â”‚ â”‚ # â€¢ Shows â€œSelected by HRâ€ when manual
â”‚ â”‚ â”‚ # â€¢ Context-aware âœ¨ AI suggest (polish drafts or generate)
â”‚ â”‚ â”‚ # â€¢ Save changes (store-only; no rebuild)
â”‚ â”‚ â”‚ # â€¢ Save as custom template (store-only)
â”‚ â”‚ â”‚ # â€¢ ğŸ—‘ Remove this role from the hiring plan
â”‚ â”‚ â””â”€ unresolved_role_panel.py # Suggestions UI (dropdown + live preview):
â”‚ â”‚ # â€¢ De-dupes already-chosen templates
â”‚ â”‚ # â€¢ Create-new flow (mission + skills/responsibilities with âœ¨ AI assist)
â”‚ â”‚ # â€¢ Marks role as matched (manual) when selected/created
â”‚ â”œâ”€ services/
â”‚ â”‚ â”œâ”€ init.py
â”‚ â”‚ â””â”€ state_helpers.py # field/set_field/_get helpers + bump_llm_usage; lightweight store-only updates
â”‚ â”œâ”€ graph/
â”‚ â”‚ â”œâ”€ init.py
â”‚ â”‚ â”œâ”€ state.py # AppState, RoleSpec (confidence Optional, confidence_source), JD models
â”‚ â”‚ â”œâ”€ nodes.py # Intake (LLM-first + heuristic), top-3 suggests, profile fill-only, JD compose/polish
â”‚ â”‚ â””â”€ graph_builder.py # LangGraph wiring (delays plan/JD generation until explicitly triggered)
â”‚ â””â”€ tools/
â”‚ â”œâ”€ init.py
â”‚ â”œâ”€ role_matcher.py # Data paths; timestamped custom ids; created_at; improved extractor; top-3 matching
â”‚ â”œâ”€ llm_extractor.py # Optional LLM-based role extraction (strict JSON response)
â”‚ â”œâ”€ search_stub.py # Robust template loader (curated/custom) for dicts or models; file/role_id/title fallback
â”‚ â”œâ”€ skill_suggester.py # Context-aware âœ¨ AI: mission + must/nice + responsibilities (polish drafts or generate)
â”‚ â”œâ”€ checklist.py # Generates hiring plan/checklist & loop (LLM-powered with timeline/budget/location context)
â”‚ â”œâ”€ email_writer.py # Outreach email templates
â”‚ â”œâ”€ inclusive_check.py # Inclusive language linter
â”‚ â”œâ”€ simulator.py # Success estimator
â”‚ â”œâ”€ analytics.py # Simple CSV logger (includes click_review_roles, etc.)
â”‚ â””â”€ exporters.py # Exports:
â”‚ # â€¢ plan.docx (timeline, checklist, loop, Roles & JDs summary)
â”‚ # â€¢ per-role JD .docx and ZIP bundle
â”œâ”€ data/
â”‚ â”œâ”€ roles_kb.json # Curated role index
â”‚ â”œâ”€ roles_kb_custom.json # Custom role index (includes created_at)
â”‚ â”œâ”€ role_knowledge/ # Curated templates (canonical schema: skills.{must,nice})
â”‚ â”‚ â”œâ”€ founding_engineer.json
â”‚ â”‚ â””â”€ genai_intern.json
â”‚ â””â”€ role_knowledge_custom/ # Custom templates (timestamped ids: <slug>__custom__YYYYMMDD_HHMMSS)
â”œâ”€ exports/ # (ignored) generated files
â”œâ”€ logs/ # (ignored) usage logs
â”œâ”€ Dockerfile
â”œâ”€ .dockerignore
â”œâ”€ requirements.txt
â””â”€ .gitignore

```

---

## How it flows (LangGraph)

```
User prompt
â†“
[Intake]

Extract intended roles from the full prompt:
â€¢ LLM-first (optional, respects use_llm/llm_cap) â†’ titles
â€¢ Heuristic fallback (supports 1..N roles) â†’ titles

For each title, fuzzy-match against roles_kb.json + roles_kb_custom.json

Produce RoleSpec(status="suggest" | "unknown") with top-3 suggestions per role
â†“
[UI Resolver â€” Roles & JDs tab]

Review role suggestions:
â€¢ For each suggested role: default-select newest custom template if present
â€¢ Exclude templates already chosen in other slots (no duplicate picks)
â€¢ Choose from a dropdown (stable indices); preview updates live
â€¢ Preview includes: Mission, Function, Seniority, Must/Nice, Responsibilities
â€¢ â€œUse selected suggestionâ€ marks the role as matched:
â€“ Sets confidence=None and confidence_source="manual" (â€œSelected by HRâ€)

Create a brand-new custom role (alternative to picking a suggestion):
â€¢ Fields: Title, Function, Seniority, Mission, Must/Nice, Responsibilities
â€¢ âœ¨ Suggest with AI (context-aware): polish current drafts or generate from scratch (respects LLM cap)
â€¢ Save â†’ persists to data/role_knowledge_custom/<slug>__custom__YYYYMMDD_HHMMSS.json
and indexes in data/roles_kb_custom.json (created_at)

Add another hiring role (global action on this tab):
â€¢ Enter a title â†’ see suggestions â†’ pick one OR create a custom role (same flow as above)
â€¢ Newly added role appears as â€œsuggestâ€ until confirmed

Edit matched roles inline:
â€¢ Update Title/Seniority/Must/Nice/Responsibilities
â€¢ âœ¨ Suggest with AI (context-aware) to refine existing drafts
â€¢ Save changes (store-only; no rebuild)
â€¢ ğŸ—‘ Remove this role from the hiring plan (store-only)

Once all roles are finalized â†’ RoleSpec(status="match") for each

Click Generate plan & JDs:
â€¢ Rebuilds Job Descriptions and the Hiring Plan using the current set of matched roles
â€¢ Heavy compute happens here (not during every small edit)
â†“
[Profile (enrich-only)]

Load curated/custom JSON template for each matched role

FILL ONLY MISSING FIELDS (skills.must, skills.nice, responsibilities, seniority, geo)

Never overwrite fields already edited in UI
â†“
[JD]

Build structured Job Descriptions per matched role (includes role-specific Mission)

(Optional) LLM polish (strict JSON in/out; capped by llm_cap)
â†“
[Plan]

Generate checklist + interview loop (Markdown + JSON) using timeline_weeks, budget_usd, location_policy,
and role/JD context

Inclusive language scan

Outreach emails (only for finalized roles)
â†“
[UI Tabs]

Roles & JDs
â€¢ Resolve suggestions, add roles, create custom roles
â€¢ Edit matched roles, âœ¨ context-aware re-suggest, Save (no rebuild), ğŸ—‘ Remove role
â€¢ Generate plan & JDs to refresh outputs after all roles are ready

Checklist / Plan

Tools (Inclusive warnings / Outreach email examples / LLM usage log)

Export
â€¢ Hiring Plan â†’ MD / JSON / DOCX (timeline/budget/location, checklist, loop, role summaries)
â€¢ Per-role JDs â†’ one DOCX per role
â€¢ All JDs â†’ ZIP
```

Notes:
- Apply changes updates only the current run; Save as custom template persists to disk.
- Custom roles are stored under data/role_knowledge_custom/ and indexed in data/roles_kb_custom.json.
- All AI features respect use_llm/llm_cap and log usage in global_constraints.llm_log.

---


## Local Setup

**Requirements:** Python 3.10+ (3.11 recommended)

```bash
# clone + enter
pip install -r requirements.txt
```

Optional: create .env in the project root to enable LLM polish:
OPENAI_API_KEY=sk-...

Run:
streamlit run app/ui.py

Open the local URL Streamlit prints (default http://localhost:8501).

---

## LLM Toggle & Cost Guard

- Toggle **Use LLM to polish JD text** in the UI.
- The JD step will call OpenAI **only if**:
  - The toggle is **ON**, and
  - `OPENAI_API_KEY` is available, and
  - The per-run **call cap** has **not** been exceeded (configurable in the UI).
- The **Tools** tab shows an **LLM usage log** (model + token counts when provided).

> Without a key or with the toggle OFF, the app is fully deterministic.

---

## Exports

- **Markdown:** `plan.md`
- **JSON:** `plan.json`
- **DOCX:** `plan.docx` (HR-friendly, ready to share or print as PDF)

Download these in the **Export** tab.  
`plan.md` / `plan.json` are also written to `exports/` (local, ignored by Git).

---

## Security & Data

- Secrets are **not** committed. `.env` and `key.env` are ignored by `.gitignore`.
- Role data is synthetic templates under `data/role_knowledge/`.
- No real candidate PII; all outputs are demo-safe.

---

## Deploy to AWS Elastic Beanstalk (Docker)

This repo includes a `Dockerfile` and `.dockerignore`.

### One-time

```bash
pip install awsebcli
aws configure   # set your AWS creds/region
```

Initialize (pick your region)

```bash
# example: us-west-1
eb init -p docker HiringAssistant-EB --region us-west-1
```

Create a load-balanced environment (needed for HTTPS via ALB)
```bash
eb create hiring-assistant-lb --elb-type application
eb setenv PORT=8080 OPENAI_API_KEY=sk-xxxx
eb deploy
eb open
```

The Dockerfile binds Streamlit to 0.0.0.0:8080, which matches EBâ€™s expectations.

---

## Roadmap (Next Up)

- Clarifying Questions node (ask for missing budget/timeline/skills, then continue)

- Rubric Generator node (competency anchors 1â€“4 + sample questions)

- Simulator tab (sliders for funnel rates â†’ probability & bottleneck)

- Session memory (persist company profile/preferences)

- Analytics dashboard (basic charts for conversions & load)

---

## Known Limitations

- Role parsing is intentionally simple (keyword-based).

- Local exports/logs are ephemeral on EB (container filesystem). Use S3/DB for persistence in production.

---

## Credits

Built by Anh with guidance from a ChatGPT coding assistant. Uses Streamlit, LangGraph, OpenAI, Pydantic, and Python-docx